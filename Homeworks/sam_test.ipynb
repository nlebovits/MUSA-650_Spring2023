{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-04-29T10:40:42.311765Z",
     "end_time": "2023-04-29T10:41:20.938052Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nissim\\AppData\\Local\\R-MINI~1\\envs\\remote-sensing\\lib\\site-packages\\requests\\__init__.py:109: RequestsDependencyWarning: urllib3 (1.26.15) or chardet (None)/charset_normalizer (3.1.0) doesn't match a supported version!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import leafmap\n",
    "import torch\n",
    "from samgeo import SamGeo, tms_to_geotiff, get_basemaps\n",
    "from skimage import io\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import rasterio\n",
    "\n",
    "# import a single tif from the indirectory\n",
    "indir = \"G:/.shortcut-targets-by-id/1w3kIfvkBH_Xa1G856qbgk-8u0IRdcwZ3/MUSA 650 Final Project\"\n",
    "\n",
    "# set the filepath\n",
    "tifs_path = os.path.join(indir, \"tifs\")\n",
    "\n",
    "# create an empty list to store the tif files\n",
    "tif_list = []\n",
    "\n",
    "# loop through all tif files in the folder and append to the list\n",
    "for file in os.listdir(tifs_path):\n",
    "    if file.endswith(\".tif\"):\n",
    "        tif_file = os.path.join(tifs_path, file)\n",
    "        with rasterio.open(tif_file) as src:\n",
    "            # read the tif file and append to the list\n",
    "            tif_data = src.read(1, masked=True)\n",
    "            tif_list.append(tif_data)\n",
    "    print(f\"Processed file: {file}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-29T10:06:07.977752Z",
     "end_time": "2023-04-29T10:08:13.411136Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import rasterio.plot\n",
    "\n",
    "data_name = \"G:/.shortcut-targets-by-id/1w3kIfvkBH_Xa1G856qbgk-8u0IRdcwZ3/MUSA 650 Final Project/tifs/site1.tif\"\n",
    "tiff = rasterio.open(data_name)\n",
    "rasterio.plot.show(tiff, title = \"Site 1\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-29T10:10:38.307295Z",
     "end_time": "2023-04-29T10:10:40.160044Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# print a list of all tifs in the tif_list\n",
    "tif_list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-29T10:09:12.076739Z",
     "end_time": "2023-04-29T10:09:12.110608Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import rasterio.plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(tif_list[0], cmap='gray')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-29T10:00:48.354304Z",
     "end_time": "2023-04-29T10:00:49.412428Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import rasterio\n",
    "\n",
    "# import a single tif from the indirectory\n",
    "indir = \"G:/.shortcut-targets-by-id/1w3kIfvkBH_Xa1G856qbgk-8u0IRdcwZ3/MUSA 650 Final Project\"\n",
    "\n",
    "# set the filepath\n",
    "tifs_path = os.path.join(indir, \"tifs\")\n",
    "\n",
    "# create an empty list to store the tif files\n",
    "tif_list = []\n",
    "\n",
    "\n",
    "# loop through all tif files in the folder and append to the list\n",
    "for file in os.listdir(tifs_path):\n",
    "    if file.endswith(\".tif\"):\n",
    "        tif_file = os.path.join(tifs_path, file)\n",
    "        # read the tif file and normalize the data\n",
    "        tif_data = io.imread(tif_file).astype(np.float32)\n",
    "        tif_data /= 255.0\n",
    "        tif_data -= np.mean(tif_data)\n",
    "        tif_list.append(tif_data)\n",
    "\n",
    "# convert the list to a numpy array\n",
    "tifs = np.array(tif_list)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-26T18:04:32.053807Z",
     "end_time": "2023-04-26T18:05:10.794075Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tif_list[0].plot()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-26T18:09:08.648085Z",
     "end_time": "2023-04-26T18:09:08.653091Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/154 [1:33:50<239:18:59, 5630.98s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 21\u001B[0m\n\u001B[0;32m     11\u001B[0m device \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m     13\u001B[0m sam \u001B[38;5;241m=\u001B[39m SamGeo(\n\u001B[0;32m     14\u001B[0m     model_type\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvit_h\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m     15\u001B[0m     device\u001B[38;5;241m=\u001B[39mdevice,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     18\u001B[0m     sam_kwargs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m     19\u001B[0m )\n\u001B[1;32m---> 21\u001B[0m \u001B[43msam\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[43min_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout_path\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\R-MINI~1\\envs\\remote-sensing\\lib\\site-packages\\samgeo\\samgeo.py:112\u001B[0m, in \u001B[0;36mSamGeo.generate\u001B[1;34m(self, in_path, out_path, **kwargs)\u001B[0m\n\u001B[0;32m    104\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mgenerate\u001B[39m(\u001B[38;5;28mself\u001B[39m, in_path, out_path, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    105\u001B[0m     \u001B[38;5;124;03m\"\"\"Segment the input image and save the result to the output path.\u001B[39;00m\n\u001B[0;32m    106\u001B[0m \n\u001B[0;32m    107\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m    108\u001B[0m \u001B[38;5;124;03m        in_path (str): The path to the input image.\u001B[39;00m\n\u001B[0;32m    109\u001B[0m \u001B[38;5;124;03m        out_path (str): The path to the output image.\u001B[39;00m\n\u001B[0;32m    110\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 112\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m tiff_to_tiff(in_path, out_path, \u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Local\\R-MINI~1\\envs\\remote-sensing\\lib\\site-packages\\samgeo\\common.py:677\u001B[0m, in \u001B[0;36mtiff_to_tiff\u001B[1;34m(src_fp, dst_fp, func, data_to_rgb, sample_size, sample_resize, bound)\u001B[0m\n\u001B[0;32m    672\u001B[0m     uint8_rgb_in \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mresize(\n\u001B[0;32m    673\u001B[0m         uint8_rgb_in, resize_hw, interpolation\u001B[38;5;241m=\u001B[39mcv2\u001B[38;5;241m.\u001B[39mINTER_LINEAR\n\u001B[0;32m    674\u001B[0m     )\n\u001B[0;32m    676\u001B[0m \u001B[38;5;66;03m# Do something\u001B[39;00m\n\u001B[1;32m--> 677\u001B[0m uin8_out \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43muint8_rgb_in\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    679\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m resize_hw \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    680\u001B[0m     uin8_out \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mresize(\n\u001B[0;32m    681\u001B[0m         uin8_out, orig_size, interpolation\u001B[38;5;241m=\u001B[39mcv2\u001B[38;5;241m.\u001B[39mINTER_NEAREST\n\u001B[0;32m    682\u001B[0m     )\n",
      "File \u001B[1;32m~\\AppData\\Local\\R-MINI~1\\envs\\remote-sensing\\lib\\site-packages\\samgeo\\samgeo.py:88\u001B[0m, in \u001B[0;36mSamGeo.__call__\u001B[1;34m(self, image)\u001B[0m\n\u001B[0;32m     85\u001B[0m resulting_mask \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mzeros((h, w), dtype\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39muint8)\n\u001B[0;32m     86\u001B[0m resulting_borders \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mzeros((h, w), dtype\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39muint8)\n\u001B[1;32m---> 88\u001B[0m masks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmask_generator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimage\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     89\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m m \u001B[38;5;129;01min\u001B[39;00m masks:\n\u001B[0;32m     90\u001B[0m     mask \u001B[38;5;241m=\u001B[39m (m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msegmentation\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m)\u001B[38;5;241m.\u001B[39mastype(np\u001B[38;5;241m.\u001B[39muint8)\n",
      "File \u001B[1;32m~\\AppData\\Local\\R-MINI~1\\envs\\remote-sensing\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001B[0m, in \u001B[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m     26\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclone():\n\u001B[1;32m---> 27\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Local\\R-MINI~1\\envs\\remote-sensing\\lib\\site-packages\\segment_anything\\automatic_mask_generator.py:163\u001B[0m, in \u001B[0;36mSamAutomaticMaskGenerator.generate\u001B[1;34m(self, image)\u001B[0m\n\u001B[0;32m    138\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    139\u001B[0m \u001B[38;5;124;03mGenerates masks for the given image.\u001B[39;00m\n\u001B[0;32m    140\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    159\u001B[0m \u001B[38;5;124;03m         the mask, given in XYWH format.\u001B[39;00m\n\u001B[0;32m    160\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    162\u001B[0m \u001B[38;5;66;03m# Generate masks\u001B[39;00m\n\u001B[1;32m--> 163\u001B[0m mask_data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_generate_masks\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimage\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    165\u001B[0m \u001B[38;5;66;03m# Filter small disconnected regions and holes in masks\u001B[39;00m\n\u001B[0;32m    166\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmin_mask_region_area \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[1;32m~\\AppData\\Local\\R-MINI~1\\envs\\remote-sensing\\lib\\site-packages\\segment_anything\\automatic_mask_generator.py:206\u001B[0m, in \u001B[0;36mSamAutomaticMaskGenerator._generate_masks\u001B[1;34m(self, image)\u001B[0m\n\u001B[0;32m    204\u001B[0m data \u001B[38;5;241m=\u001B[39m MaskData()\n\u001B[0;32m    205\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m crop_box, layer_idx \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(crop_boxes, layer_idxs):\n\u001B[1;32m--> 206\u001B[0m     crop_data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_process_crop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcrop_box\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlayer_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morig_size\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    207\u001B[0m     data\u001B[38;5;241m.\u001B[39mcat(crop_data)\n\u001B[0;32m    209\u001B[0m \u001B[38;5;66;03m# Remove duplicate masks between crops\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\R-MINI~1\\envs\\remote-sensing\\lib\\site-packages\\segment_anything\\automatic_mask_generator.py:245\u001B[0m, in \u001B[0;36mSamAutomaticMaskGenerator._process_crop\u001B[1;34m(self, image, crop_box, crop_layer_idx, orig_size)\u001B[0m\n\u001B[0;32m    243\u001B[0m data \u001B[38;5;241m=\u001B[39m MaskData()\n\u001B[0;32m    244\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m (points,) \u001B[38;5;129;01min\u001B[39;00m batch_iterator(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpoints_per_batch, points_for_image):\n\u001B[1;32m--> 245\u001B[0m     batch_data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_process_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpoints\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcropped_im_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcrop_box\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morig_size\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    246\u001B[0m     data\u001B[38;5;241m.\u001B[39mcat(batch_data)\n\u001B[0;32m    247\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m batch_data\n",
      "File \u001B[1;32m~\\AppData\\Local\\R-MINI~1\\envs\\remote-sensing\\lib\\site-packages\\segment_anything\\automatic_mask_generator.py:279\u001B[0m, in \u001B[0;36mSamAutomaticMaskGenerator._process_batch\u001B[1;34m(self, points, im_size, crop_box, orig_size)\u001B[0m\n\u001B[0;32m    277\u001B[0m in_points \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mas_tensor(transformed_points, device\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredictor\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m    278\u001B[0m in_labels \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mones(in_points\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m], dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mint, device\u001B[38;5;241m=\u001B[39min_points\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[1;32m--> 279\u001B[0m masks, iou_preds, _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredictor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict_torch\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    280\u001B[0m \u001B[43m    \u001B[49m\u001B[43min_points\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    281\u001B[0m \u001B[43m    \u001B[49m\u001B[43min_labels\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    282\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmultimask_output\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    283\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_logits\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    284\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    286\u001B[0m \u001B[38;5;66;03m# Serialize predictions and store in MaskData\u001B[39;00m\n\u001B[0;32m    287\u001B[0m data \u001B[38;5;241m=\u001B[39m MaskData(\n\u001B[0;32m    288\u001B[0m     masks\u001B[38;5;241m=\u001B[39mmasks\u001B[38;5;241m.\u001B[39mflatten(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m),\n\u001B[0;32m    289\u001B[0m     iou_preds\u001B[38;5;241m=\u001B[39miou_preds\u001B[38;5;241m.\u001B[39mflatten(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m),\n\u001B[0;32m    290\u001B[0m     points\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mas_tensor(points\u001B[38;5;241m.\u001B[39mrepeat(masks\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m], axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)),\n\u001B[0;32m    291\u001B[0m )\n",
      "File \u001B[1;32m~\\AppData\\Local\\R-MINI~1\\envs\\remote-sensing\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001B[0m, in \u001B[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m     26\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclone():\n\u001B[1;32m---> 27\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Local\\R-MINI~1\\envs\\remote-sensing\\lib\\site-packages\\segment_anything\\predictor.py:229\u001B[0m, in \u001B[0;36mSamPredictor.predict_torch\u001B[1;34m(self, point_coords, point_labels, boxes, mask_input, multimask_output, return_logits)\u001B[0m\n\u001B[0;32m    222\u001B[0m sparse_embeddings, dense_embeddings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mprompt_encoder(\n\u001B[0;32m    223\u001B[0m     points\u001B[38;5;241m=\u001B[39mpoints,\n\u001B[0;32m    224\u001B[0m     boxes\u001B[38;5;241m=\u001B[39mboxes,\n\u001B[0;32m    225\u001B[0m     masks\u001B[38;5;241m=\u001B[39mmask_input,\n\u001B[0;32m    226\u001B[0m )\n\u001B[0;32m    228\u001B[0m \u001B[38;5;66;03m# Predict masks\u001B[39;00m\n\u001B[1;32m--> 229\u001B[0m low_res_masks, iou_predictions \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmask_decoder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    230\u001B[0m \u001B[43m    \u001B[49m\u001B[43mimage_embeddings\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfeatures\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    231\u001B[0m \u001B[43m    \u001B[49m\u001B[43mimage_pe\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprompt_encoder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_dense_pe\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    232\u001B[0m \u001B[43m    \u001B[49m\u001B[43msparse_prompt_embeddings\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msparse_embeddings\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    233\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdense_prompt_embeddings\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdense_embeddings\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    234\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmultimask_output\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmultimask_output\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    235\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    237\u001B[0m \u001B[38;5;66;03m# Upscale the masks to the original image resolution\u001B[39;00m\n\u001B[0;32m    238\u001B[0m masks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mpostprocess_masks(low_res_masks, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minput_size, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moriginal_size)\n",
      "File \u001B[1;32m~\\AppData\\Local\\R-MINI~1\\envs\\remote-sensing\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\AppData\\Local\\R-MINI~1\\envs\\remote-sensing\\lib\\site-packages\\segment_anything\\modeling\\mask_decoder.py:94\u001B[0m, in \u001B[0;36mMaskDecoder.forward\u001B[1;34m(self, image_embeddings, image_pe, sparse_prompt_embeddings, dense_prompt_embeddings, multimask_output)\u001B[0m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m     73\u001B[0m     image_embeddings: torch\u001B[38;5;241m.\u001B[39mTensor,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     77\u001B[0m     multimask_output: \u001B[38;5;28mbool\u001B[39m,\n\u001B[0;32m     78\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[torch\u001B[38;5;241m.\u001B[39mTensor, torch\u001B[38;5;241m.\u001B[39mTensor]:\n\u001B[0;32m     79\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     80\u001B[0m \u001B[38;5;124;03m    Predict masks given image and prompt embeddings.\u001B[39;00m\n\u001B[0;32m     81\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     92\u001B[0m \u001B[38;5;124;03m      torch.Tensor: batched predictions of mask quality\u001B[39;00m\n\u001B[0;32m     93\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m---> 94\u001B[0m     masks, iou_pred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict_masks\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     95\u001B[0m \u001B[43m        \u001B[49m\u001B[43mimage_embeddings\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mimage_embeddings\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     96\u001B[0m \u001B[43m        \u001B[49m\u001B[43mimage_pe\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mimage_pe\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     97\u001B[0m \u001B[43m        \u001B[49m\u001B[43msparse_prompt_embeddings\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msparse_prompt_embeddings\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     98\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdense_prompt_embeddings\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdense_prompt_embeddings\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     99\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    101\u001B[0m     \u001B[38;5;66;03m# Select the correct mask or masks for output\u001B[39;00m\n\u001B[0;32m    102\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m multimask_output:\n",
      "File \u001B[1;32m~\\AppData\\Local\\R-MINI~1\\envs\\remote-sensing\\lib\\site-packages\\segment_anything\\modeling\\mask_decoder.py:132\u001B[0m, in \u001B[0;36mMaskDecoder.predict_masks\u001B[1;34m(self, image_embeddings, image_pe, sparse_prompt_embeddings, dense_prompt_embeddings)\u001B[0m\n\u001B[0;32m    129\u001B[0m b, c, h, w \u001B[38;5;241m=\u001B[39m src\u001B[38;5;241m.\u001B[39mshape\n\u001B[0;32m    131\u001B[0m \u001B[38;5;66;03m# Run the transformer\u001B[39;00m\n\u001B[1;32m--> 132\u001B[0m hs, src \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransformer\u001B[49m\u001B[43m(\u001B[49m\u001B[43msrc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpos_src\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtokens\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    133\u001B[0m iou_token_out \u001B[38;5;241m=\u001B[39m hs[:, \u001B[38;5;241m0\u001B[39m, :]\n\u001B[0;32m    134\u001B[0m mask_tokens_out \u001B[38;5;241m=\u001B[39m hs[:, \u001B[38;5;241m1\u001B[39m : (\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_mask_tokens), :]\n",
      "File \u001B[1;32m~\\AppData\\Local\\R-MINI~1\\envs\\remote-sensing\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\AppData\\Local\\R-MINI~1\\envs\\remote-sensing\\lib\\site-packages\\segment_anything\\modeling\\transformer.py:92\u001B[0m, in \u001B[0;36mTwoWayTransformer.forward\u001B[1;34m(self, image_embedding, image_pe, point_embedding)\u001B[0m\n\u001B[0;32m     90\u001B[0m \u001B[38;5;66;03m# Apply transformer blocks and final layernorm\u001B[39;00m\n\u001B[0;32m     91\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayers:\n\u001B[1;32m---> 92\u001B[0m     queries, keys \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     93\u001B[0m \u001B[43m        \u001B[49m\u001B[43mqueries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mqueries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     94\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkeys\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkeys\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     95\u001B[0m \u001B[43m        \u001B[49m\u001B[43mquery_pe\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpoint_embedding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     96\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkey_pe\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mimage_pe\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     97\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     99\u001B[0m \u001B[38;5;66;03m# Apply the final attention layer from the points to the image\u001B[39;00m\n\u001B[0;32m    100\u001B[0m q \u001B[38;5;241m=\u001B[39m queries \u001B[38;5;241m+\u001B[39m point_embedding\n",
      "File \u001B[1;32m~\\AppData\\Local\\R-MINI~1\\envs\\remote-sensing\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\AppData\\Local\\R-MINI~1\\envs\\remote-sensing\\lib\\site-packages\\segment_anything\\modeling\\transformer.py:178\u001B[0m, in \u001B[0;36mTwoWayAttentionBlock.forward\u001B[1;34m(self, queries, keys, query_pe, key_pe)\u001B[0m\n\u001B[0;32m    176\u001B[0m q \u001B[38;5;241m=\u001B[39m queries \u001B[38;5;241m+\u001B[39m query_pe\n\u001B[0;32m    177\u001B[0m k \u001B[38;5;241m=\u001B[39m keys \u001B[38;5;241m+\u001B[39m key_pe\n\u001B[1;32m--> 178\u001B[0m attn_out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcross_attn_image_to_token\u001B[49m\u001B[43m(\u001B[49m\u001B[43mq\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mk\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mv\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mqueries\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    179\u001B[0m keys \u001B[38;5;241m=\u001B[39m keys \u001B[38;5;241m+\u001B[39m attn_out\n\u001B[0;32m    180\u001B[0m keys \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnorm4(keys)\n",
      "File \u001B[1;32m~\\AppData\\Local\\R-MINI~1\\envs\\remote-sensing\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\AppData\\Local\\R-MINI~1\\envs\\remote-sensing\\lib\\site-packages\\segment_anything\\modeling\\transformer.py:220\u001B[0m, in \u001B[0;36mAttention.forward\u001B[1;34m(self, q, k, v)\u001B[0m\n\u001B[0;32m    218\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, q: Tensor, k: Tensor, v: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m    219\u001B[0m     \u001B[38;5;66;03m# Input projections\u001B[39;00m\n\u001B[1;32m--> 220\u001B[0m     q \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mq_proj\u001B[49m\u001B[43m(\u001B[49m\u001B[43mq\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    221\u001B[0m     k \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mk_proj(k)\n\u001B[0;32m    222\u001B[0m     v \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mv_proj(v)\n",
      "File \u001B[1;32m~\\AppData\\Local\\R-MINI~1\\envs\\remote-sensing\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\AppData\\Local\\R-MINI~1\\envs\\remote-sensing\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001B[0m, in \u001B[0;36mLinear.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 114\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from samgeo import SamGeo, tms_to_geotiff\n",
    "\n",
    "base_path = \"G:/.shortcut-targets-by-id/1w3kIfvkBH_Xa1G856qbgk-8u0IRdcwZ3/MUSA 650 Final Project/tifs\"\n",
    "\n",
    "in_path = os.path.join(base_path, \"site1.tif\")\n",
    "\n",
    "out_path = os.path.join(base_path, \"site1_mask.tif\")\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "sam = SamGeo(\n",
    "    model_type='vit_h',\n",
    "    device=device,\n",
    "    erosion_kernel=(3, 3),\n",
    "    mask_multiplier=255,\n",
    "    sam_kwargs=None,\n",
    ")\n",
    "\n",
    "sam.generate(in_path, out_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "invalid path or file: array([[[  0.,   0.,   0.],\n        [  0.,   0.,   0.],\n        [  0.,   0.,   0.],\n        ...,\n        [  0.,   0.,   0.],\n        [  0.,   0.,   0.],\n        [  0.,   0.,   0.]],\n\n       [[  0.,   0.,   0.],\n        [255., 255., 255.],\n        [255., 255., 255.],\n        ...,\n        [  0.,   0.,   0.],\n        [  0.,   0.,   0.],\n        [  0.,   0.,   0.]],\n\n       [[  0.,   0.,   0.],\n        [255., 255., 255.],\n        [255., 255., 255.],\n        ...,\n        [  0.,   0.,   0.],\n        [  0.,   0.,   0.],\n        [  0.,   0.,   0.]],\n\n       ...,\n\n       [[  0.,   0.,   0.],\n        [  0.,   0.,   0.],\n        [  0.,   0.,   0.],\n        ...,\n        [255., 255., 255.],\n        [255., 255., 255.],\n        [  0.,   0.,   0.]],\n\n       [[  0.,   0.,   0.],\n        [  0.,   0.,   0.],\n        [  0.,   0.,   0.],\n        ...,\n        [255., 255., 255.],\n        [255., 255., 255.],\n        [  0.,   0.,   0.]],\n\n       [[  0.,   0.,   0.],\n        [  0.,   0.,   0.],\n        [  0.,   0.,   0.],\n        ...,\n        [  0.,   0.,   0.],\n        [  0.,   0.,   0.],\n        [  0.,   0.,   0.]]], dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 23\u001B[0m\n\u001B[0;32m     14\u001B[0m sam \u001B[38;5;241m=\u001B[39m SamGeo(\n\u001B[0;32m     15\u001B[0m     model_type\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvit_h\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m     16\u001B[0m     device\u001B[38;5;241m=\u001B[39mdevice,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     19\u001B[0m     sam_kwargs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m     20\u001B[0m )\n\u001B[0;32m     22\u001B[0m mask \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msegment.tiff\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m---> 23\u001B[0m \u001B[43msam\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmask\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     25\u001B[0m vector \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msegment.gpkg\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m     26\u001B[0m sam\u001B[38;5;241m.\u001B[39mtiff_to_gpkg(mask, vector, simplify_tolerance\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\R-MINI~1\\envs\\remote-sensing\\lib\\site-packages\\samgeo\\samgeo.py:112\u001B[0m, in \u001B[0;36mSamGeo.generate\u001B[1;34m(self, in_path, out_path, **kwargs)\u001B[0m\n\u001B[0;32m    104\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mgenerate\u001B[39m(\u001B[38;5;28mself\u001B[39m, in_path, out_path, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    105\u001B[0m     \u001B[38;5;124;03m\"\"\"Segment the input image and save the result to the output path.\u001B[39;00m\n\u001B[0;32m    106\u001B[0m \n\u001B[0;32m    107\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m    108\u001B[0m \u001B[38;5;124;03m        in_path (str): The path to the input image.\u001B[39;00m\n\u001B[0;32m    109\u001B[0m \u001B[38;5;124;03m        out_path (str): The path to the output image.\u001B[39;00m\n\u001B[0;32m    110\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 112\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m tiff_to_tiff(in_path, out_path, \u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Local\\R-MINI~1\\envs\\remote-sensing\\lib\\site-packages\\samgeo\\common.py:648\u001B[0m, in \u001B[0;36mtiff_to_tiff\u001B[1;34m(src_fp, dst_fp, func, data_to_rgb, sample_size, sample_resize, bound)\u001B[0m\n\u001B[0;32m    639\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtiff_to_tiff\u001B[39m(\n\u001B[0;32m    640\u001B[0m     src_fp,\n\u001B[0;32m    641\u001B[0m     dst_fp,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    646\u001B[0m     bound\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m128\u001B[39m,\n\u001B[0;32m    647\u001B[0m ):\n\u001B[1;32m--> 648\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43mrasterio\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43msrc_fp\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m src:\n\u001B[0;32m    649\u001B[0m         profile \u001B[38;5;241m=\u001B[39m src\u001B[38;5;241m.\u001B[39mprofile\n\u001B[0;32m    651\u001B[0m         \u001B[38;5;66;03m# Computer blocks\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\R-MINI~1\\envs\\remote-sensing\\lib\\site-packages\\rasterio\\env.py:437\u001B[0m, in \u001B[0;36mensure_env_with_credentials.<locals>.wrapper\u001B[1;34m(*args, **kwds)\u001B[0m\n\u001B[0;32m    434\u001B[0m     session \u001B[38;5;241m=\u001B[39m DummySession()\n\u001B[0;32m    436\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m env_ctor(session\u001B[38;5;241m=\u001B[39msession):\n\u001B[1;32m--> 437\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m f(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n",
      "File \u001B[1;32m~\\AppData\\Local\\R-MINI~1\\envs\\remote-sensing\\lib\\site-packages\\rasterio\\__init__.py:157\u001B[0m, in \u001B[0;36mopen\u001B[1;34m(fp, mode, driver, width, height, count, crs, transform, dtype, nodata, sharing, **kwargs)\u001B[0m\n\u001B[0;32m    155\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(fp, \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m    156\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mhasattr\u001B[39m(fp, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mread\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(fp, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mwrite\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(fp, Path)):\n\u001B[1;32m--> 157\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minvalid path or file: \u001B[39m\u001B[38;5;132;01m{0!r}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(fp))\n\u001B[0;32m    158\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mode \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(mode, \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m    159\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minvalid mode: \u001B[39m\u001B[38;5;132;01m{0!r}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(mode))\n",
      "\u001B[1;31mTypeError\u001B[0m: invalid path or file: array([[[  0.,   0.,   0.],\n        [  0.,   0.,   0.],\n        [  0.,   0.,   0.],\n        ...,\n        [  0.,   0.,   0.],\n        [  0.,   0.,   0.],\n        [  0.,   0.,   0.]],\n\n       [[  0.,   0.,   0.],\n        [255., 255., 255.],\n        [255., 255., 255.],\n        ...,\n        [  0.,   0.,   0.],\n        [  0.,   0.,   0.],\n        [  0.,   0.,   0.]],\n\n       [[  0.,   0.,   0.],\n        [255., 255., 255.],\n        [255., 255., 255.],\n        ...,\n        [  0.,   0.,   0.],\n        [  0.,   0.,   0.],\n        [  0.,   0.,   0.]],\n\n       ...,\n\n       [[  0.,   0.,   0.],\n        [  0.,   0.,   0.],\n        [  0.,   0.,   0.],\n        ...,\n        [255., 255., 255.],\n        [255., 255., 255.],\n        [  0.,   0.,   0.]],\n\n       [[  0.,   0.,   0.],\n        [  0.,   0.,   0.],\n        [  0.,   0.,   0.],\n        ...,\n        [255., 255., 255.],\n        [255., 255., 255.],\n        [  0.,   0.,   0.]],\n\n       [[  0.,   0.,   0.],\n        [  0.,   0.,   0.],\n        [  0.,   0.,   0.],\n        ...,\n        [  0.,   0.,   0.],\n        [  0.,   0.,   0.],\n        [  0.,   0.,   0.]]], dtype=float32)"
     ]
    }
   ],
   "source": [
    "\n",
    "vector = 'segment.gpkg'\n",
    "sam.tiff_to_gpkg(mask, vector, simplify_tolerance=None)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "m = leafmap.Map(center=[29.676840, -95.369222], zoom=19)\n",
    "m.add_basemap('SATELLITE')\n",
    "m"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-29T10:35:11.405262Z",
     "end_time": "2023-04-29T10:35:11.443376Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-29T10:36:59.264033Z",
     "end_time": "2023-04-29T10:37:01.979538Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
